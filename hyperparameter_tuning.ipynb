{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import scipy\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import *\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "!pip install ucimlrepo\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select initial population\n",
    "\n",
    "# build models\n",
    "# assemble costs\n",
    "# convert costs into probability distribution\n",
    "# compute new population (e.g. using expected value or sampling probability distribution)\n",
    "\n",
    "# repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hypothesis: statistically-significant improvement (needs to be well-defined)\n",
    "\n",
    "# Control:\n",
    "# Baseline with random uniform sampling and brute force model building\n",
    "\n",
    "# Experimental:\n",
    "# Several cycles of tuning heuristic such that total number of models is less than that of control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter and Baseline Testing Classes, I/O Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Hyperparameter():\n",
    "    def __init__(self, sample_func, low, high, dtype):\n",
    "        self.sample_f = sample_func\n",
    "        self.low = low\n",
    "        self.high = high\n",
    "        self.cast = dtype\n",
    "    def change_bounds(self, low_new, high_new):\n",
    "        self.low = low_new\n",
    "        self.high = high_new\n",
    "    def sample(self):\n",
    "        return self.sample_f(self.low, self.high)\n",
    "    def sample_uniform(self, low, high):\n",
    "        return np.random.uniform(low=low, high=high, size=None)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class Baseline():\n",
    "    def __init__(self, hparams, n_models, data_func, model_func):\n",
    "        self.hyperparameters = hparams # dictionary of Hyperparameter objects\n",
    "        self.num_models = n_models\n",
    "        self.build_model = model_func\n",
    "        self.X_t, self.y_t, self.X_v, self.y_v = data_func()\n",
    "        self.all_hyperparameters = {key: [] for key, value in self.hyperparameters.items()}\n",
    "        self.losses = []\n",
    "        self.accuracies = []\n",
    "\n",
    "    def train_models(self):\n",
    "        for i in range(self.num_models):\n",
    "            print(\"Model\", str(i + 1), \": \")\n",
    "            hparam_values = {}\n",
    "            for hparam_name, hparam_object in self.hyperparameters.items():\n",
    "                hparam_value = self.hyperparameters[hparam_name].sample()\n",
    "                hparam_values[hparam_name] = hparam_value\n",
    "                self.all_hyperparameters[hparam_name].append(hparam_value)\n",
    "                print(hparam_name + \": \", str(hparam_value))\n",
    "            loss, accuracy = self.build_model(hparam_values, self.X_t, self.y_t, self.X_v, self.y_v)\n",
    "            self.losses.append(loss)\n",
    "            self.accuracies.append(accuracy)\n",
    "            print(\"Loss:\", str(loss))\n",
    "            print(\"Accuracy:\", str(accuracy))\n",
    "            print()\n",
    "        result = pd.DataFrame(self.all_hyperparameters).join(pd.DataFrame({\"loss\": self.losses})).join(pd.DataFrame({\"accuracy\": self.accuracies}))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prepare_ann_data():\n",
    "    breast_cancer_wisconsin_diagnostic = fetch_ucirepo(id=17) \n",
    "    X = breast_cancer_wisconsin_diagnostic.data.features.values\n",
    "    y = breast_cancer_wisconsin_diagnostic.data.targets.values\n",
    "    y[y==[\"M\"]] = 1\n",
    "    y[y==[\"B\"]] = 0\n",
    "    y = y.reshape(-1).astype(\"float32\")\n",
    "    X_t, X_v, y_t, y_v = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "    means = np.mean(X_t, axis=0)\n",
    "    stddevs = np.std(X_t, axis=0)\n",
    "    X_t = (X_t - means) / stddevs\n",
    "    X_v = (X_v - means) / stddevs\n",
    "    return X_t, y_t, X_v, y_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def build_ann(hparams_list, X_t, y_t, X_v, y_v):\n",
    "    learning_rate = 1e-3\n",
    "    num_units = 16\n",
    "    dropout_rate = 0.6\n",
    "    if \"learning_rate\" in hparams_list:\n",
    "        learning_rate = hparams_list[\"learning_rate\"]\n",
    "    if \"num_units\" in hparams_list:\n",
    "        num_units = hparams_list[\"num_units\"]\n",
    "    if \"dropout_rate\" in hparams_list:\n",
    "        dropout_rate = hparams_list[\"dropout_rate\"]\n",
    "    input = Input(shape=(X_t.shape[1:]))\n",
    "    x = Dense(num_units, activation=\"relu\")(input)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    x = Dense(4, activation=\"relu\")(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    output = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=input, outputs=output)\n",
    "\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=learning_rate), loss=\"binary_crossentropy\", metrics=[\"binary_accuracy\"])\n",
    "    history = model.fit(X_t, y_t, validation_data=(X_v, y_v), batch_size=64, epochs=20, verbose=False)\n",
    "    result = model.evaluate(X_v, y_v, verbose=False)\n",
    "    loss = result[0]\n",
    "    accuracy = result[1]\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prepare_cnn_data():\n",
    "    (X_t, y_t), (X_v, y_v) = fashion_mnist.load_data()\n",
    "    X_t = np.expand_dims(X_t, axis=-1).astype(\"float32\") / 255.0\n",
    "    X_v = np.expand_dims(X_v, axis=-1).astype(\"float32\") / 255.0\n",
    "    y_t = to_categorical(y_t)\n",
    "    y_v = to_categorical(y_v)\n",
    "    return X_t, y_t, X_v, y_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def build_cnn(hparams_list, X_t, y_t, X_v, y_v):\n",
    "    learning_rate = 1e-3\n",
    "    num_filters = 32\n",
    "    if \"learning_rate\" in hparams_list:\n",
    "        learning_rate = hparams_list[\"learning_rate\"]\n",
    "    if \"num_filters\" in hparams_list:\n",
    "        num_filters = hparams_list[\"num_filters\"]\n",
    "    input = Input(shape=(X_t.shape[1:]))\n",
    "    x = Conv2D(16, (3,3), padding=\"same\", activation=\"relu\")(input)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Conv2D(num_filters, (3,3), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Conv2D(32, (3,3), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = MaxPooling2D((2,2))(x)\n",
    "    x = Flatten()(x)\n",
    "    output = Dense(10, activation=\"softmax\")(x)\n",
    "    model = Model(inputs=input, outputs=output)\n",
    "\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=learning_rate), loss=\"categorical_crossentropy\", metrics=[\"categorical_accuracy\"])\n",
    "    history = model.fit(X_t, y_t, validation_data=(X_v, y_v), batch_size=64, epochs=10, verbose=False)\n",
    "    result = model.evaluate(X_v, y_v, verbose=False)\n",
    "    loss = result[0]\n",
    "    accuracy = result[1]\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def prepare_rnn_data(lookback=None):\n",
    "    def create_examples(X, y, lookback, pred_size=10, test_size=0.2):\n",
    "        X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
    "        y = (y - np.mean(y)) / np.std(y)\n",
    "        X_new = []\n",
    "        Y_new = []\n",
    "        for i in range(0, X.shape[0] - lookback - pred_size):\n",
    "            X_new.append(X[i:i + lookback, :])\n",
    "            Y_new.append(y[i + lookback:i + lookback + pred_size])\n",
    "        X_new = np.array(X_new)\n",
    "        Y_new = np.array(Y_new)\n",
    "        split = X_new.shape[0] - int(test_size * X_new.shape[0])\n",
    "        X_t = X_new[:split]\n",
    "        X_v = X_new[split:]\n",
    "        y_t = Y_new[:split]\n",
    "        y_v = Y_new[split:]\n",
    "        return X_t, y_t, X_v, y_v\n",
    "    if lookback == None:\n",
    "        return None, None, None, None\n",
    "    rolling_window = 100\n",
    "    nth = 5\n",
    "    air_quality = fetch_ucirepo(id=360) \n",
    "    X = air_quality.data.features \n",
    "    y = air_quality.data.targets \n",
    "    subset = air_quality.data.features[[\"PT08.S1(CO)\",\"C6H6(GT)\",\"PT08.S2(NMHC)\",\"PT08.S3(NOx)\",\"PT08.S4(NO2)\",\"PT08.S5(O3)\",\"RH\",\"AH\",\"T\"]]\n",
    "    subset = subset[np.sum(subset == -200, axis=1) == 0]\n",
    "    X = subset.iloc[:,:-1]\n",
    "    y = subset.iloc[:,-1]\n",
    "    X = X.rolling(window=rolling_window).mean().iloc[rolling_window:].iloc[::nth].reset_index(drop=True).values\n",
    "    y = y.rolling(window=rolling_window).mean().iloc[rolling_window:].iloc[::nth].reset_index(drop=True).values\n",
    "    X_t, y_t, X_v, y_v = create_examples(X, y, lookback=lookback)\n",
    "    return X_t, y_t, X_v, y_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def build_rnn(hparams_list, X_t, y_t, X_v, y_v):\n",
    "    X_t, y_t, X_v, y_v = prepare_rnn_data(lookback=hparams_list[\"lookback\"])\n",
    "    num_units = 16\n",
    "    if \"num_units\" in hparams_list:\n",
    "        num_units = hparams_list[\"num_units\"]\n",
    "    input = Input(shape=(X_t.shape[1:]))\n",
    "    x = LSTM(num_units, activation=\"tanh\")(input)\n",
    "    output = Dense(10)(x)\n",
    "    model = Model(inputs=input, outputs=output)\n",
    "\n",
    "    model.compile(optimizer=optimizers.Adam(learning_rate=1e-3), loss=\"mae\", metrics=[\"mse\"])\n",
    "#     es = callbacks.EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=25, restore_best_weights=True)\n",
    "    history = model.fit(X_t, y_t, validation_data=(X_v, y_v), batch_size=64, epochs=40, verbose=False)\n",
    "    result = model.evaluate(X_v, y_v, verbose=False)\n",
    "    loss = result[0]\n",
    "    accuracy = result[1]\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ANN\n",
    "num_units = Hyperparameter(lambda l, h: np.random.randint(low=l, high=h), low=1, high=64, dtype=int)\n",
    "dropout_rate = Hyperparameter(lambda l, h: np.random.uniform(low=l, high=h), low=0.0, high=1.0, dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "num_units_dropout_rate_baseline = Baseline(hparams={\"num_units\": num_units, \"dropout_rate\": dropout_rate}, \n",
    "                                           n_models=50, data_func=prepare_ann_data, model_func=build_ann)\n",
    "num_units_dropout_rate_results = num_units_dropout_rate_baseline.train_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# CNN\n",
    "lr = Hyperparameter(lambda l, h: 10 ** np.random.uniform(low=l, high=h), low=-4, high=-1, dtype=float)\n",
    "num_filters = Hyperparameter(lambda l, h: np.random.randint(low=l, high=h), low=4, high=65, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "lr_num_filters_baseline = Baseline(hparams={\"learning_rate\": lr, \"num_filters\": num_filters}, \n",
    "                                   n_models=50, data_func=prepare_cnn_data, model_func=build_cnn)\n",
    "lr_num_filters_results = lr_num_filters_baseline.train_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# RNN\n",
    "lookback = Hyperparameter(lambda l, h: np.random.randint(low=l, high=h), low=2, high=120, dtype=int)\n",
    "num_units = Hyperparameter(lambda l, h: np.random.randint(low=l, high=h), low=1, high=128, dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "lookback_num_units_baseline = Baseline(hparams={\"lookback\": lookback, \"num_units\": num_units}, \n",
    "                                       n_models=50, data_func=prepare_rnn_data, model_func=build_rnn)\n",
    "lookback_num_units_results = lookback_num_units_baseline.train_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experimental Testing\n",
    "## Probabilistic Heuristics for Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class HyperparameterTuning(Baseline):\n",
    "    def __init__(self, hparams, n_models, data_func, model_func):\n",
    "        super().__init__(hparams, n_models, data_func, model_func)\n",
    "        self.cycle_num = 0\n",
    "        self.weight = 0.2\n",
    "        self.num_cycles = 4\n",
    "\n",
    "    def sample_new(self, losses):\n",
    "        inverted_losses = 1 - (losses - np.min(losses)) / (np.max(losses) - np.min(losses))\n",
    "        weighting_factor = 3 # to make probability differences more pronounced\n",
    "        discrete_pmf = scipy.special.softmax(weighting_factor * inverted_losses)\n",
    "        return np.random.choice(losses.shape[0], p=discrete_pmf)\n",
    "\n",
    "    def update_cycle(self):\n",
    "        self.cycle_num += 1\n",
    "        self.weight /= 1.5 # weight = 0.2 / (1.5 ** cycle_num)\n",
    "        self.num_models = int(self.num_models / 1.5)\n",
    "\n",
    "    def tuning_step(self, result):\n",
    "        losses = result[\"loss\"].values\n",
    "        print(\"Losses:\", losses)\n",
    "        new_hyperparameters = {key: [] for key, value in self.hyperparameters.items()}\n",
    "        new_losses = []\n",
    "        new_accuracies = []\n",
    "        for i in range(self.num_models):\n",
    "            print(\"Cycle\", str(self.cycle_num), \"Model\", str(i + 1), \": \")\n",
    "            if self.num_models == 1:\n",
    "                idx = np.argmin(losses)\n",
    "                print(\"Idx:\", idx)\n",
    "            else:\n",
    "                idx = self.sample_new(losses)\n",
    "            hparam_values = {}\n",
    "            for hparam_name, hparam_object in self.hyperparameters.items():\n",
    "                hparam_value_mean = result[hparam_name][idx]\n",
    "                print(\"Hparam value mean:\", hparam_value_mean)\n",
    "                hparam_value = hparam_object.sample_uniform(hparam_value_mean * (1 - self.weight), hparam_value_mean * (1 + self.weight))\n",
    "                # hparam_object.change_bounds(hparam_value_mean * (1 - self.weight), hparam_value_mean * (1 + self.weight))\n",
    "                hparam_value = hparam_object.cast(hparam_value)\n",
    "                hparam_values[hparam_name] = hparam_value\n",
    "                new_hyperparameters[hparam_name].append(hparam_value)\n",
    "                print(hparam_name + \": \", str(hparam_value))\n",
    "            loss, accuracy = self.build_model(hparam_values, self.X_t, self.y_t, self.X_v, self.y_v)\n",
    "            new_losses.append(loss)\n",
    "            new_accuracies.append(accuracy)\n",
    "            print(\"Loss: \", str(loss))\n",
    "            print(\"Accuracy: \", str(accuracy))\n",
    "            print()\n",
    "        new_result = pd.DataFrame({\"cycle\": [self.cycle_num for i in range(self.num_models)]}).join(pd.DataFrame(new_hyperparameters).join(pd.DataFrame({\"loss\": new_losses})).join(pd.DataFrame({\"accuracy\": new_accuracies})))\n",
    "#         result = result.append(new_result).reset_index(drop=True)\n",
    "        result = pd.concat([result, new_result], ignore_index=True)\n",
    "        return result\n",
    "\n",
    "    def run_heuristic(self):\n",
    "        result = self.train_models() # train initial population\n",
    "        result = pd.DataFrame({\"cycle\": [self.cycle_num for i in range(self.num_models)]}).join(result)\n",
    "        for i in range(self.num_cycles):\n",
    "            self.update_cycle()\n",
    "            result = self.tuning_step(result)\n",
    "            if self.num_models == 1:\n",
    "                break\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ANN\n",
    "num_units_dropout_rate_tuning = HyperparameterTuning(hparams={\"num_units\": num_units, \"dropout_rate\": dropout_rate}, \n",
    "                                                     n_models=10, data_func=prepare_ann_data, model_func=build_ann)\n",
    "ann_result = num_units_dropout_rate_tuning.run_heuristic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# CNN\n",
    "lr_num_filters_tuning = HyperparameterTuning(hparams={\"learning_rate\": lr, \"num_filters\": num_filters}, \n",
    "                                             n_models=10, data_func=prepare_cnn_data, model_func=build_cnn)\n",
    "cnn_result = lr_num_filters_tuning.run_heuristic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# RNN\n",
    "lookback_num_units_tuning = HyperparameterTuning(hparams={\"lookback\": lookback, \"num_units\": num_units}, \n",
    "                                                 n_models=10, data_func=prepare_rnn_data, model_func=build_rnn)\n",
    "rnn_result = lookback_num_units_tuning.run_heuristic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plot_results(result):\n",
    "    plt.plot([np.mean(result[result[\"cycle\"]==i][\"loss\"]) for i in range(np.max(result[\"cycle\"]) + 1)], linestyle=\"--\", marker=\"o\")\n",
    "    plt.plot([np.median(result[result[\"cycle\"]==i][\"loss\"]) for i in range(np.max(result[\"cycle\"]) + 1)], linestyle=\"--\", marker=\"o\")\n",
    "    plt.plot([np.max(result[result[\"cycle\"]==i][\"loss\"]) for i in range(np.max(result[\"cycle\"]) + 1)], linestyle=\"--\", marker=\"o\")\n",
    "    plt.plot([np.min(result[result[\"cycle\"]==i][\"loss\"]) for i in range(np.max(result[\"cycle\"]) + 1)], linestyle=\"--\", marker=\"o\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_csv(file, name):\n",
    "    file.to_csv(\"results/\" + name + \".csv\")"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [],
   "dockerImageVersionId": 30665,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
